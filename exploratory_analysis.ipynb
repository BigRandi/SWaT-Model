{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc6cd31f-c140-45a3-840b-2764c844ea8b",
   "metadata": {},
   "source": [
    "# Exploratory Analysis\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587e1c49-5636-4efe-9684-2958a9b79486",
   "metadata": {},
   "source": [
    "This code imports zipped data files from an S3 bucket, determines the shape and size of the data frame (Pandas), detects outliers/NAN/Null values, calculates collumn-wise mean/median/mode/stddev, and performs some correlation analysis on the variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246cccc1-f395-4ef9-ac67-a00f8bd3b638",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Dependencies & Functions\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e536a4-13e2-4728-b479-056878f9af8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import boto3\n",
    "import botocore\n",
    "import sagemaker\n",
    "import numpy as np\n",
    "\n",
    "#this is a test\n",
    "def eda(df):\n",
    "    # Source: https://gist.github.com/jiahao87/c97214065f996b76ab8fe4ca1964b2b5\n",
    "    \n",
    "    \"\"\"Given dataframe, generate exploratory data analysis\"\"\"\n",
    "    # check that input is pandas dataframe\n",
    "    if type(df) != pd.core.frame.DataFrame:\n",
    "        raise TypeError(\"Only pandas dataframe is allowed as input\")\n",
    "        \n",
    "    # replace field that's entirely space (or empty) with NaN\n",
    "    df = df.replace(r'^\\s*$', np.nan, regex=True)\n",
    "\n",
    "    print(\"Preview of data:\")\n",
    "    display(df.head(3))\n",
    "\n",
    "    print(\"\\nTo check: \\n (1) Total number of entries \\n (2) Column types \\n (3) Any null values\\n\")\n",
    "    print(df.info())\n",
    "\n",
    "    # generate preview of entries with null values\n",
    "    if df.isnull().any(axis=None):\n",
    "        print(\"\\nPreview of data with null values:\")\n",
    "        display(df[df.isnull().any(axis=1)].head(3))\n",
    "        missingno.matrix(df)\n",
    "        plt.show()\n",
    "\n",
    "    # generate count statistics of duplicate entries\n",
    "    if len(df[df.duplicated()]) > 0:\n",
    "        print(\"\\n***Number of duplicated entries: \", len(df[df.duplicated()]))\n",
    "        display(df[df.duplicated(keep=False)].sort_values(by=list(df.columns)).head())\n",
    "    else:\n",
    "        print(\"\\nNo duplicated entries found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2fce03-d2f7-4979-b958-c1edcf5c1f06",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Import Data\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fe61d59d-41f9-4d95-9123-84550af8548f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training input/output will be stored in: s3://exploratoryanalysis-swat/analysis_artifacts\n",
      "Downloaded training data will be read from s3://exploratoryanalysis-swat/dataset_unzipped\n"
     ]
    }
   ],
   "source": [
    "# Import dataset from S3 Bucket\n",
    "\n",
    "bucket = \"exploratoryanalysis-swat\"             # Bucket location for working directory\n",
    "prefix = \"analysis_artifacts\"                   # Folder location for working directory\n",
    "\n",
    "# S3 bucket where the original data is downloaded and stored.\n",
    "downloaded_data_bucket = \"exploratoryanalysis-swat\"    # Bucket location for data directory\n",
    "downloaded_data_prefix = \"dataset_unzipped\"            # Folder location of data files\n",
    "\n",
    "# Housekeeping, sagemaker gets execution role and reigon from this sagemaker instance\n",
    "execution_role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "# Check bucket existence and permissions\n",
    "def check_bucket_permission(bucket):\n",
    "    # check if the bucket exists\n",
    "    permission = False\n",
    "    try:\n",
    "        boto3.Session().client(\"s3\").head_bucket(Bucket=bucket)\n",
    "    except botocore.exceptions.ParamValidationError as e:\n",
    "        print(\n",
    "            \"Hey! You either forgot to specify your S3 bucket\"\n",
    "            \" or you gave your bucket an invalid name!\"\n",
    "        )\n",
    "    except botocore.exceptions.ClientError as e:\n",
    "        if e.response[\"Error\"][\"Code\"] == \"403\":\n",
    "            print(f\"Hey! You don't have permission to access the bucket, {bucket}.\")\n",
    "        elif e.response[\"Error\"][\"Code\"] == \"404\":\n",
    "            print(f\"Hey! Your bucket, {bucket}, doesn't exist!\")\n",
    "        else:\n",
    "            raise\n",
    "    else:\n",
    "        permission = True\n",
    "    return permission\n",
    "\n",
    "\n",
    "if check_bucket_permission(bucket):\n",
    "    print(f\"Training input/output will be stored in: s3://{bucket}/{prefix}\")\n",
    "if check_bucket_permission(downloaded_data_bucket):\n",
    "    print(f\"Downloaded training data will be read from s3://{downloaded_data_bucket}/{downloaded_data_prefix}\")\n",
    "# Future development: expand for more data upload options, perhaps a filepath instead"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1621dc17-9437-4743-8395-4c6bc54b2710",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Classify & Organize\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fea88f-5825-4107-9184-fa66dd5f67f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Organize and qualify data\n",
    "\n",
    "# Input file name here\n",
    "data_filename = \"SWaT_Dataset_Normal_v1_01.csv\"\n",
    "\n",
    "# Download S3 data file to Sagemaker space\n",
    "s3 = boto3.client(\"s3\")\n",
    "s3.download_file(downloaded_data_bucket, f\"{downloaded_data_prefix}/{data_filename}\", data_filename)\n",
    "\n",
    "# Read file into Pandas Dataframe \n",
    "sensor_data = pd.read_csv(data_filename)\n",
    "\n",
    "# Establish Shape of raw sensor data\n",
    "raw_data_shape = sensor_data.shape\n",
    "print(\"Data file dimensions:\", raw_data_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68b04a5-83f8-4cfa-b54e-ea54781ce9e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eda(sensor_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216f6536-0926-4a8c-b05c-c8ae53185b2b",
   "metadata": {},
   "source": [
    "# Clean Data\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7dac741-e1c9-42de-bf5f-31866e848e6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Locate NAN values and store indicies\n",
    "nan_values = sensor_data[sensor_data.isna().any(axis=1)]\n",
    "if nan_values.empty:\n",
    "    pass\n",
    "else:\n",
    "    # Determine what we want to do with the missing fields\n",
    "    print('There are NAN values in the data')\n",
    "    \n",
    "    \n",
    "# I already know that there is a misspelling of the word \"Attack\" that reads \"A ttack\" which will need to be cleaned in the attack version of the dataset.\n",
    "# This cleaning has been performed within the .csv direclty\n",
    "\n",
    "# I also see another issue where the SWaT Attack dataset does not have the P1, P2, ... P5 headers above the individual collumns\n",
    "# This has been corrected by removing the process headers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d34b72-e2d3-4421-8c4c-c7d809ddf43c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Analyze Data\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a38fb3c-e9fb-44ab-b79c-77ac9fcd6efa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Determine mean, median, std dev, etc. of each collumn\n",
    "data_statistics = sensor_data.describe()\n",
    "print(\"Dataset statistics for each column:\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "display(data_statistics)\n",
    "\n",
    "#print(data_statistics, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b715185c-f54f-4b96-9357-f09c33727c96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# What are the unique values and counts for each categorical column\n",
    "unique_values = sensor_data.nunique(axis=0)\n",
    "print(\"Number of unique values for each column in dataset:\")\n",
    "display(unique_values)\n",
    "\n",
    "# Which columns have only a single unique value? (Constants)\n",
    "print(\"\\nColumns with constant values:\")\n",
    "constant_columns = unique_values.where(unique_values==1).dropna(how='all')\n",
    "print(constant_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc9507f-2398-4890-b2bd-0854aeb3b872",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Outliers\n",
    "Z Score tells us how many standard deviations each value is from the mean. Anything outside of 3 STD deviations is an outlier and anything outside 2 is in the farthest 5% and could be cut <br>\n",
    "IQR determines the range between the 25th and 75th percentile <br>\n",
    "Anything that lies 1.5*(range) above or below these quartiles is considered an outlier <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037e2f7a-4f31-43c5-9bf5-2ce6072a0fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locate and classify outliers\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# The collumns include two objects: a timestamp and a string. These cannot be analyzed for outliers, and will be removed by selecting only columns with numbers\n",
    "numerical_sensor_data = sensor_data.select_dtypes(include='number')\n",
    "\n",
    "# Z Score tells us how many standard deviations each value is from the mean. Anything outside of 3 STD deviations is an outlier and anything outside 2 is in the farthest 5% and could be cut\n",
    "z_scores = numerical_sensor_data.apply(stats.zscore)\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "display(z_scores.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da86ef59-61ed-418c-98cd-acc4e2ec46d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interquartile Range (IQR) is another way to classify outliers. \n",
    "# IQR determines the range between the 25th and 75th percentile\n",
    "# Then, anything that lies 1.5*(range) above or below these quartiles is considered an outlier\n",
    "# If the data value is lower than the lower range or larger than the upper range, store the index of the value.\n",
    "# Then count the number of outliers\n",
    "\n",
    "IQR = data_statistics.loc['75%'] - data_statistics.loc['25%']\n",
    "IQR = IQR.to_frame()\n",
    "IQR = IQR.transpose()\n",
    "\n",
    "# Define lower and upper ranges for each variable. Statistics does not run on timestamp or string objects. Only columns with numerical values.\n",
    "lower_range = data_statistics.loc['25%'] - 1.5 * IQR\n",
    "upper_range = data_statistics.loc['75%'] + 1.5 * IQR\n",
    "\n",
    "# The format of a query needs to be \"column label <query condition> @<variable name to be compared against>\"\n",
    "# 'FIT101<@aa' where aa is the variable that holds the limit value for this iteration\n",
    "lower_queries = ['{}<@aa'.format(k) for k in lower_range.columns]\n",
    "upper_queries = ['{}>@aa'.format(k) for k in upper_range.columns]\n",
    "\n",
    "jj = 0\n",
    "tot_upper_outl = 0\n",
    "tot_lower_outl = 0\n",
    "for column in IQR:\n",
    "    # Lower boundary check\n",
    "    aa = lower_range.iat[0,jj]                                        # ex: FIT101\n",
    "    lower_outliers = numerical_sensor_data.query(lower_queries[jj])   # ex: 'FIT101<@aa'\n",
    "    if not lower_outliers.empty:\n",
    "        print('Condition that triggered the IQR outlier: ', lower_queries[jj], aa)\n",
    "        print('Number of \"less than\" outliers', lower_outliers.shape[0], '\\n')\n",
    "        tot_lower_outl += lower_outliers.shape[0]\n",
    "    \n",
    "    # Upper Boundary Check\n",
    "    aa = upper_range.iat[0,jj]                                        # ex: FIT101\n",
    "    upper_outliers = numerical_sensor_data.query(upper_queries[jj])   # ex: 'FIT101>@aa'\n",
    "    if not upper_outliers.empty:\n",
    "        print('Condition that triggered the IQR outlier: ', upper_queries[jj], aa)\n",
    "        print('Number of \"greater than\" outliers', upper_outliers.shape[0], '\\n')\n",
    "        tot_upper_outl += upper_outliers.shape[0]\n",
    "    jj += 1\n",
    "    \n",
    "print('Total number of outliers: ', tot_lower_outl+tot_upper_outl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b8851e01-ee0d-4e3d-806d-56bb9e92c72c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIT101</th>\n",
       "      <th>LIT101</th>\n",
       "      <th>MV101</th>\n",
       "      <th>P101</th>\n",
       "      <th>AIT201</th>\n",
       "      <th>AIT202</th>\n",
       "      <th>AIT203</th>\n",
       "      <th>FIT201</th>\n",
       "      <th>MV201</th>\n",
       "      <th>P203</th>\n",
       "      <th>P205</th>\n",
       "      <th>DPIT301</th>\n",
       "      <th>FIT301</th>\n",
       "      <th>LIT301</th>\n",
       "      <th>MV301</th>\n",
       "      <th>MV302</th>\n",
       "      <th>MV303</th>\n",
       "      <th>MV304</th>\n",
       "      <th>P301</th>\n",
       "      <th>P302</th>\n",
       "      <th>AIT401</th>\n",
       "      <th>AIT402</th>\n",
       "      <th>FIT401</th>\n",
       "      <th>LIT401</th>\n",
       "      <th>P402</th>\n",
       "      <th>UV401</th>\n",
       "      <th>AIT501</th>\n",
       "      <th>AIT502</th>\n",
       "      <th>AIT503</th>\n",
       "      <th>AIT504</th>\n",
       "      <th>FIT501</th>\n",
       "      <th>FIT502</th>\n",
       "      <th>FIT503</th>\n",
       "      <th>FIT504</th>\n",
       "      <th>P501</th>\n",
       "      <th>PIT501</th>\n",
       "      <th>PIT502</th>\n",
       "      <th>PIT503</th>\n",
       "      <th>FIT601</th>\n",
       "      <th>P602</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FIT101</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.610349</td>\n",
       "      <td>0.972333</td>\n",
       "      <td>0.256764</td>\n",
       "      <td>0.015445</td>\n",
       "      <td>-0.064270</td>\n",
       "      <td>0.052884</td>\n",
       "      <td>0.263456</td>\n",
       "      <td>0.257377</td>\n",
       "      <td>0.264456</td>\n",
       "      <td>0.133282</td>\n",
       "      <td>-0.209032</td>\n",
       "      <td>-0.218082</td>\n",
       "      <td>0.233469</td>\n",
       "      <td>0.028093</td>\n",
       "      <td>-0.191265</td>\n",
       "      <td>0.068349</td>\n",
       "      <td>0.003926</td>\n",
       "      <td>0.057647</td>\n",
       "      <td>-0.238541</td>\n",
       "      <td>-0.045521</td>\n",
       "      <td>0.154326</td>\n",
       "      <td>0.031704</td>\n",
       "      <td>0.269263</td>\n",
       "      <td>0.028480</td>\n",
       "      <td>0.028352</td>\n",
       "      <td>-0.055396</td>\n",
       "      <td>0.186126</td>\n",
       "      <td>0.113274</td>\n",
       "      <td>-0.019039</td>\n",
       "      <td>0.031871</td>\n",
       "      <td>0.033896</td>\n",
       "      <td>0.025366</td>\n",
       "      <td>0.018301</td>\n",
       "      <td>0.025039</td>\n",
       "      <td>0.032426</td>\n",
       "      <td>0.068567</td>\n",
       "      <td>0.033747</td>\n",
       "      <td>0.054980</td>\n",
       "      <td>0.051000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LIT101</th>\n",
       "      <td>-0.610349</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.609546</td>\n",
       "      <td>-0.606593</td>\n",
       "      <td>-0.050169</td>\n",
       "      <td>0.130691</td>\n",
       "      <td>-0.144169</td>\n",
       "      <td>-0.614798</td>\n",
       "      <td>-0.608094</td>\n",
       "      <td>-0.613915</td>\n",
       "      <td>-0.289995</td>\n",
       "      <td>-0.143930</td>\n",
       "      <td>-0.138820</td>\n",
       "      <td>0.353102</td>\n",
       "      <td>-0.030333</td>\n",
       "      <td>-0.129274</td>\n",
       "      <td>-0.073739</td>\n",
       "      <td>-0.010313</td>\n",
       "      <td>-0.220905</td>\n",
       "      <td>-0.064634</td>\n",
       "      <td>0.103748</td>\n",
       "      <td>-0.332853</td>\n",
       "      <td>0.257520</td>\n",
       "      <td>0.139218</td>\n",
       "      <td>0.252718</td>\n",
       "      <td>0.252883</td>\n",
       "      <td>0.444454</td>\n",
       "      <td>-0.438977</td>\n",
       "      <td>-0.092055</td>\n",
       "      <td>-0.260089</td>\n",
       "      <td>0.257721</td>\n",
       "      <td>0.254285</td>\n",
       "      <td>0.257933</td>\n",
       "      <td>0.259692</td>\n",
       "      <td>0.256979</td>\n",
       "      <td>0.253455</td>\n",
       "      <td>0.010261</td>\n",
       "      <td>0.252869</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>-0.055444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MV101</th>\n",
       "      <td>0.972333</td>\n",
       "      <td>-0.609546</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.266683</td>\n",
       "      <td>0.015493</td>\n",
       "      <td>-0.065378</td>\n",
       "      <td>0.053816</td>\n",
       "      <td>0.273287</td>\n",
       "      <td>0.267042</td>\n",
       "      <td>0.274082</td>\n",
       "      <td>0.140212</td>\n",
       "      <td>-0.183593</td>\n",
       "      <td>-0.191641</td>\n",
       "      <td>0.219957</td>\n",
       "      <td>0.028272</td>\n",
       "      <td>-0.167931</td>\n",
       "      <td>0.068273</td>\n",
       "      <td>0.012059</td>\n",
       "      <td>0.057258</td>\n",
       "      <td>-0.213618</td>\n",
       "      <td>-0.045098</td>\n",
       "      <td>0.153793</td>\n",
       "      <td>0.030835</td>\n",
       "      <td>0.268360</td>\n",
       "      <td>0.027707</td>\n",
       "      <td>0.027573</td>\n",
       "      <td>-0.055617</td>\n",
       "      <td>0.185502</td>\n",
       "      <td>0.112014</td>\n",
       "      <td>-0.018345</td>\n",
       "      <td>0.031028</td>\n",
       "      <td>0.032948</td>\n",
       "      <td>0.024567</td>\n",
       "      <td>0.017578</td>\n",
       "      <td>0.024302</td>\n",
       "      <td>0.031580</td>\n",
       "      <td>0.067175</td>\n",
       "      <td>0.032872</td>\n",
       "      <td>0.054973</td>\n",
       "      <td>0.051084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P101</th>\n",
       "      <td>0.256764</td>\n",
       "      <td>-0.606593</td>\n",
       "      <td>0.266683</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013955</td>\n",
       "      <td>-0.199244</td>\n",
       "      <td>0.120240</td>\n",
       "      <td>0.992140</td>\n",
       "      <td>0.986280</td>\n",
       "      <td>0.992825</td>\n",
       "      <td>0.621157</td>\n",
       "      <td>0.533549</td>\n",
       "      <td>0.539609</td>\n",
       "      <td>-0.269606</td>\n",
       "      <td>0.026600</td>\n",
       "      <td>0.494589</td>\n",
       "      <td>0.060747</td>\n",
       "      <td>-0.005916</td>\n",
       "      <td>0.054651</td>\n",
       "      <td>0.491455</td>\n",
       "      <td>-0.019258</td>\n",
       "      <td>0.150265</td>\n",
       "      <td>0.069584</td>\n",
       "      <td>0.161638</td>\n",
       "      <td>0.068582</td>\n",
       "      <td>0.068411</td>\n",
       "      <td>-0.037984</td>\n",
       "      <td>0.166604</td>\n",
       "      <td>0.031721</td>\n",
       "      <td>-0.059783</td>\n",
       "      <td>0.069513</td>\n",
       "      <td>0.069994</td>\n",
       "      <td>0.064869</td>\n",
       "      <td>0.059683</td>\n",
       "      <td>0.064258</td>\n",
       "      <td>0.069068</td>\n",
       "      <td>0.068130</td>\n",
       "      <td>0.069575</td>\n",
       "      <td>0.052124</td>\n",
       "      <td>0.048276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AIT201</th>\n",
       "      <td>0.015445</td>\n",
       "      <td>-0.050169</td>\n",
       "      <td>0.015493</td>\n",
       "      <td>0.013955</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.028304</td>\n",
       "      <td>-0.026083</td>\n",
       "      <td>0.018081</td>\n",
       "      <td>0.009144</td>\n",
       "      <td>0.013432</td>\n",
       "      <td>0.006045</td>\n",
       "      <td>0.032588</td>\n",
       "      <td>0.022863</td>\n",
       "      <td>-0.053099</td>\n",
       "      <td>0.001178</td>\n",
       "      <td>0.019365</td>\n",
       "      <td>0.003879</td>\n",
       "      <td>0.003702</td>\n",
       "      <td>0.093513</td>\n",
       "      <td>-0.000625</td>\n",
       "      <td>0.124923</td>\n",
       "      <td>-0.301355</td>\n",
       "      <td>0.039669</td>\n",
       "      <td>-0.082884</td>\n",
       "      <td>0.070042</td>\n",
       "      <td>0.069827</td>\n",
       "      <td>0.164524</td>\n",
       "      <td>-0.096736</td>\n",
       "      <td>0.673429</td>\n",
       "      <td>-0.054363</td>\n",
       "      <td>0.039187</td>\n",
       "      <td>0.023333</td>\n",
       "      <td>0.087763</td>\n",
       "      <td>0.080933</td>\n",
       "      <td>0.064517</td>\n",
       "      <td>0.106721</td>\n",
       "      <td>0.193274</td>\n",
       "      <td>0.110224</td>\n",
       "      <td>0.003060</td>\n",
       "      <td>0.003089</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          FIT101    LIT101     MV101      P101    AIT201    AIT202    AIT203  \\\n",
       "FIT101  1.000000 -0.610349  0.972333  0.256764  0.015445 -0.064270  0.052884   \n",
       "LIT101 -0.610349  1.000000 -0.609546 -0.606593 -0.050169  0.130691 -0.144169   \n",
       "MV101   0.972333 -0.609546  1.000000  0.266683  0.015493 -0.065378  0.053816   \n",
       "P101    0.256764 -0.606593  0.266683  1.000000  0.013955 -0.199244  0.120240   \n",
       "AIT201  0.015445 -0.050169  0.015493  0.013955  1.000000 -0.028304 -0.026083   \n",
       "\n",
       "          FIT201     MV201      P203      P205   DPIT301    FIT301    LIT301  \\\n",
       "FIT101  0.263456  0.257377  0.264456  0.133282 -0.209032 -0.218082  0.233469   \n",
       "LIT101 -0.614798 -0.608094 -0.613915 -0.289995 -0.143930 -0.138820  0.353102   \n",
       "MV101   0.273287  0.267042  0.274082  0.140212 -0.183593 -0.191641  0.219957   \n",
       "P101    0.992140  0.986280  0.992825  0.621157  0.533549  0.539609 -0.269606   \n",
       "AIT201  0.018081  0.009144  0.013432  0.006045  0.032588  0.022863 -0.053099   \n",
       "\n",
       "           MV301     MV302     MV303     MV304      P301      P302    AIT401  \\\n",
       "FIT101  0.028093 -0.191265  0.068349  0.003926  0.057647 -0.238541 -0.045521   \n",
       "LIT101 -0.030333 -0.129274 -0.073739 -0.010313 -0.220905 -0.064634  0.103748   \n",
       "MV101   0.028272 -0.167931  0.068273  0.012059  0.057258 -0.213618 -0.045098   \n",
       "P101    0.026600  0.494589  0.060747 -0.005916  0.054651  0.491455 -0.019258   \n",
       "AIT201  0.001178  0.019365  0.003879  0.003702  0.093513 -0.000625  0.124923   \n",
       "\n",
       "          AIT402    FIT401    LIT401      P402     UV401    AIT501    AIT502  \\\n",
       "FIT101  0.154326  0.031704  0.269263  0.028480  0.028352 -0.055396  0.186126   \n",
       "LIT101 -0.332853  0.257520  0.139218  0.252718  0.252883  0.444454 -0.438977   \n",
       "MV101   0.153793  0.030835  0.268360  0.027707  0.027573 -0.055617  0.185502   \n",
       "P101    0.150265  0.069584  0.161638  0.068582  0.068411 -0.037984  0.166604   \n",
       "AIT201 -0.301355  0.039669 -0.082884  0.070042  0.069827  0.164524 -0.096736   \n",
       "\n",
       "          AIT503    AIT504    FIT501    FIT502    FIT503    FIT504      P501  \\\n",
       "FIT101  0.113274 -0.019039  0.031871  0.033896  0.025366  0.018301  0.025039   \n",
       "LIT101 -0.092055 -0.260089  0.257721  0.254285  0.257933  0.259692  0.256979   \n",
       "MV101   0.112014 -0.018345  0.031028  0.032948  0.024567  0.017578  0.024302   \n",
       "P101    0.031721 -0.059783  0.069513  0.069994  0.064869  0.059683  0.064258   \n",
       "AIT201  0.673429 -0.054363  0.039187  0.023333  0.087763  0.080933  0.064517   \n",
       "\n",
       "          PIT501    PIT502    PIT503    FIT601      P602  \n",
       "FIT101  0.032426  0.068567  0.033747  0.054980  0.051000  \n",
       "LIT101  0.253455  0.010261  0.252869 -0.059752 -0.055444  \n",
       "MV101   0.031580  0.067175  0.032872  0.054973  0.051084  \n",
       "P101    0.069068  0.068130  0.069575  0.052124  0.048276  \n",
       "AIT201  0.106721  0.193274  0.110224  0.003060  0.003089  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Correlation analysis\n",
    "# Are there any correlations between the different columns in the data?\n",
    "# Display correlation matrix\n",
    "\n",
    "# First, drop all the columns with constant values. These will not impact a correlation matrix.\n",
    "variable_sensor_data = sensor_data.drop(constant_columns.index, axis=1)\n",
    "\n",
    "correlation_matrix = variable_sensor_data.corr()\n",
    "pd.set_option('display.max_columns', None)\n",
    "display(correlation_matrix.head())\n",
    "\n",
    "# Threshold value (c\n",
    "threshold_upper = 0.5\n",
    "threshold_lower = -0.5\n",
    "threshold_corr_matrix = correlation_matrix[(correlation_matrix > threshold_upper)]\n",
    "\n",
    "# Upload correlation matrix CSV to S3 Artifacts\n",
    "filename = 'correlation_matrix.csv'\n",
    "correlation_matrix.to_csv(filename)\n",
    "\n",
    "s3.upload_file(\n",
    "    Filename=filename,\n",
    "    Bucket=bucket,\n",
    "    Key=f\"{prefix}/{filename}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec9e55b-bb85-419d-82ad-ca83886f299e",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e547f361-71d0-4960-8392-861d1e78f95b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Box Plot\n",
    "# We need to decide which values box plots are appropriate for. Numerical data with sufficient variation (not a binary 1 or 0)\n",
    "import matplotlib.pyplot as plt\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.set_title('Tank Levels ')\n",
    "ax1.boxplot([sensor_data.LIT101,sensor_data.LIT301, sensor_data.LIT401])\n",
    "ax1.set_xticklabels(['LIT101','LIT301','LIT401'])\n",
    "plt.show(fig1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93552704-81e1-483e-9e3d-92db83810a91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot data for visual representation\n",
    "# Note: The quantity of data means it takes a very long time to run. We might want to get a larger instance before doing heavy plotting.\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(sensor_data.Timestamp.loc[1:1500],sensor_data.P201.loc[1:1500])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62648b76-4bec-4ce1-8f80-620e0812b245",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sensor_data.head()"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
